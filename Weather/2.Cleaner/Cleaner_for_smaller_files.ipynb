{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#take data from each file\n",
    "#delete first 8 rows\n",
    "#Delete everything from column A that is not a date\n",
    "#make sure dates are in the same format\n",
    "#order everything by dates\n",
    "#keep only one header \n",
    "#I want to make sure there are no missing months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from Constants_for_smaller_files import stations_mapping\n",
    "\n",
    "def clean_excel_files(directory,station_name):\n",
    "    all_data = []\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, engine='openpyxl')\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file} due to error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Remove rows 1-8\n",
    "        df = df.iloc[8:]\n",
    "\n",
    "        mask_8888 = df == 8888\n",
    "        mask_9999 = df == 9999\n",
    "        \n",
    "        # Sets the values to pd.NA where the mask is True.\n",
    "        df = df.mask(mask_8888 | mask_9999, pd.NA)\n",
    "        \n",
    "        # Select columns B to J (assuming 0-based index, so columns 1 to 9)\n",
    "        columns_to_convert = df.columns[1:10]\n",
    "        \n",
    "        # Convert these specific columns to numeric, setting errors='coerce' to handle non-numeric data\n",
    "        df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Interpolate the selected columns\n",
    "        df[columns_to_convert] = df[columns_to_convert].interpolate(axis=0)\n",
    "\n",
    "\n",
    "        # Convert column A to datetime, setting errors='coerce' to handle non-date entries\n",
    "        df[df.columns[0]] = pd.to_datetime(df[df.columns[0]], format='%d-%m-%Y', errors='coerce')\n",
    "        \n",
    "        # Drop rows where the first column (dates) is NaT (Not a Time)\n",
    "        df = df.dropna(subset=[df.columns[0]])\n",
    "        \n",
    "        # Rename the first column to 'Date'\n",
    "        df = df.rename(columns={\n",
    "            df.columns[0]: 'Date',          \n",
    "            df.columns[1]: f'Tn({station_name})',           \n",
    "            df.columns[2]: f'Tx({station_name})',\n",
    "            df.columns[3]: f'Tavg({station_name})',          \n",
    "            df.columns[4]: f'RH_avg({station_name})',           \n",
    "            df.columns[5]: f'RR({station_name})',\n",
    "            df.columns[6]: f'ss({station_name})',          \n",
    "            df.columns[7]: f'ff_x({station_name})',           \n",
    "            df.columns[8]: f'ddd_x({station_name})',\n",
    "            df.columns[9]: f'ff_avg({station_name})',           \n",
    "            df.columns[10]: f'ddd_car({station_name})'\n",
    "        })\n",
    "        \n",
    "        # Reset index\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        all_data.append(df)\n",
    "\n",
    "        df.drop(df.columns[10], axis=1, inplace=True)\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No valid Excel files found.\")\n",
    "        return None\n",
    "    \n",
    "    # Merge all data\n",
    "    merged_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Check if 'Date' column exists\n",
    "    if 'Date' not in merged_df.columns:\n",
    "        print(\"The 'Date' column is missing in the merged DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by Date\n",
    "    merged_df = merged_df.sort_values(by='Date')\n",
    "    \n",
    "    # Reset index after sorting\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "    merged_df = merged_df.drop_duplicates(subset=['Date'])\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        for station_name, directory in stations_mapping.items():\n",
    "            merged_data = clean_excel_files(directory,station_name)\n",
    "            if merged_data is not None:\n",
    "                # Save the merged data to a new Excel file\n",
    "                merged_data.to_excel(f'cleaned_data_{station_name}.xlsx', index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA positions saved to 'na_positions.xlsx'\n",
      "NA summary saved to 'na_summary.xlsx'\n",
      "Merged file with filled values saved to 'merged_file_filled.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing the Excel files\n",
    "directory = './'\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\") or filename.endswith(\".xls\"):\n",
    "        if filename.startswith(\"~$\"):\n",
    "            # Skip temporary files created by Excel\n",
    "            continue\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            # Read each Excel file, specifying the engine\n",
    "            df = pd.read_excel(file_path, engine='openpyxl')\n",
    "            # Check if the 'Date' column exists\n",
    "            if 'Date' in df.columns:\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                print(f\"Skipping {file_path}: 'Date' column not found\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "if len(dfs) > 0:\n",
    "    # Merge dataframes on the 'Date' column\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='Date', how='outer')\n",
    "\n",
    "    # Sort the merged dataframe by date\n",
    "    merged_df = merged_df.sort_values(by='Date')\n",
    "\n",
    "    # Fill missing values using forward fill and backward fill\n",
    "    merged_df = merged_df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    na_positions = merged_df.isna()\n",
    "\n",
    "    # Save the positions of the NAs (True indicates an NA position)\n",
    "    na_positions.to_excel('na_positions.xlsx', index=False)\n",
    "\n",
    "    # Save the summary of NAs (count of NAs per column)\n",
    "    na_summary = merged_df.isna().sum()\n",
    "    na_summary.to_excel('na_summary.xlsx', header=[\"Count\"])\n",
    "\n",
    "    # Save the merged dataframe with filled values to a new Excel file\n",
    "    merged_df.to_excel('All_Files_Merged.xlsx', index=False)\n",
    "\n",
    "    print(\"NA positions saved to 'na_positions.xlsx'\")\n",
    "    print(\"NA summary saved to 'na_summary.xlsx'\")\n",
    "    print(\"Merged file with filled values saved to 'merged_file_filled.xlsx'\")\n",
    "else:\n",
    "    print(\"No valid Excel files found in the directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
