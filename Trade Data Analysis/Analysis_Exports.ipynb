{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    TAXUD_SMP\n",
      "0 2014-11-01  57017.12426\n",
      "1 2014-12-01  63557.94567\n",
      "2 2015-01-01  59881.75056\n",
      "3 2015-02-01  56514.28904\n",
      "4 2015-03-01  72528.12546\n",
      "5 2015-04-01  58598.02309\n",
      "6 2015-05-01  54430.25917\n",
      "7 2015-06-01  62359.12788\n",
      "8 2015-07-01  50562.91617\n",
      "9 2015-08-01  64058.01096\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from constants import Y_mapping, years_filtered, headers\n",
    "from utils import process_calendar_year, process_crop_year  # Import functions\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dfs_Ys = []\n",
    "\n",
    "for product in Y_mapping:\n",
    "    sector = product[\"sector\"]\n",
    "    year_type = product['year']\n",
    "    HS_codes = product[\"HS codes\"]\n",
    "    product_name = product[\"name\"]  # Access the name field\n",
    "\n",
    "    #Hiding the source. Even though it's public - not many stakeholders aware of it. \n",
    "    url = f\"XXXXXX&sectors={sector}&{HS_codes}\"\n",
    "    headers = headers\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json() \n",
    "    else:\n",
    "        print(\"Failed to retrieve data\")\n",
    "        data = None\n",
    "\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        if year_type == 'calendar':\n",
    "            monthly_data = process_calendar_year(df,product_name)\n",
    "        else:\n",
    "            monthly_data = process_crop_year(df,product_name)\n",
    "        \n",
    "        monthly_data = monthly_data.rename(columns={'kgEquivalent': product_name})  # Rename column with product name\n",
    "        dfs_Ys.append(monthly_data)\n",
    "    else:\n",
    "        print(\"No data to convert to DataFrame\")\n",
    "\n",
    "# Merge all DataFrames on 'date'\n",
    "if dfs_Ys:\n",
    "    merged_df = dfs_Ys[0]\n",
    "    for df in dfs_Ys[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date', how='outer').dropna()\n",
    "    \n",
    "    # Optionally rename the date column if needed\n",
    "    merged_df = merged_df.rename(columns={'date': 'Date'})\n",
    "\n",
    "    # Print the merged DataFrame\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"No dataframes to merge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_script.py\n",
    "import os\n",
    "from database_connection import query_data\n",
    "\n",
    "\n",
    "a_ssh_host = \"XXXX\"\n",
    "a_ssh_user = \"XXXX\"\n",
    "a_ssh_port = \"XXXX\"\n",
    "a_ssh_private_key = \"XXXX\"\n",
    "a_sql_hostname = \"XXXX\"\n",
    "a_sql_username = \"XXXX\"\n",
    "a_sql_password = \"XXXX\"\n",
    "a_sql_database = \"XXXX\"\n",
    "a_sql_port = \"XXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   GTT_SMP\n",
      "0 2011-01-01  40959.67\n",
      "1 2011-02-01  36941.64\n",
      "2 2011-03-01  49733.05\n",
      "3 2011-04-01  44068.32\n",
      "4 2011-05-01  45951.41\n",
      "5 2011-06-01  41445.08\n",
      "6 2011-07-01  40523.06\n",
      "7 2011-08-01  42305.13\n",
      "8 2011-09-01  50473.71\n",
      "9 2011-10-01  57250.27\n"
     ]
    }
   ],
   "source": [
    "from constants import X_mapping\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from database_connection import ssh_tunnel, db_connection, query_data\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "dfs_Xs = []\n",
    "\n",
    "with ssh_tunnel(a_ssh_host, a_ssh_port, a_ssh_user, a_ssh_private_key, a_sql_hostname, a_sql_port) as local_port:\n",
    "    with db_connection(local_port, a_sql_username, a_sql_password, a_sql_database) as conn:\n",
    "        for item in X_mapping:\n",
    "            X_code = item['X_code']\n",
    "            name = item['name']\n",
    "\n",
    "            query = f'''SELECT date, amount\n",
    "                        FROM XXXX\n",
    "                        WHERE country_id = 200 AND hs_code = {X_code} AND data_interval = 'monthly' AND type = 2 AND date > '2010-12-31'\n",
    "                        ORDER BY date ASC'''\n",
    "\n",
    "            result = query_data(conn, query)\n",
    "            result['date'] = pd.to_datetime(result['date'])\n",
    "            result = result.rename(columns={'amount': f'X_{name}'})\n",
    "\n",
    "            dfs_Xs.append(result)\n",
    "\n",
    "if dfs_Xs:\n",
    "    merged_df = dfs_Xs[0]\n",
    "    for df in dfs_Xs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date', how='outer').dropna()\n",
    "    \n",
    "    merged_df = merged_df.rename(columns={'date': 'Date'})\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"No dataframes to merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date    TAXUD_SMP   GTT_SMP\n",
      "0 2014-11-01  57017.12426  60794.67\n",
      "1 2014-12-01  63557.94567  62611.84\n",
      "2 2015-01-01  59881.75056  66746.20\n",
      "3 2015-02-01  56514.28904  58408.43\n",
      "4 2015-03-01  72528.12546  67607.55\n"
     ]
    }
   ],
   "source": [
    "all_dfs = dfs_Ys + dfs_Xs\n",
    "\n",
    "def merge_dfs_on_date(df_list):\n",
    "    merged_df = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "    return merged_df\n",
    "\n",
    "# Merge all dataframes\n",
    "merged_df = merge_dfs_on_date(all_dfs).dropna()\n",
    "\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "\n",
    "print(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  %_diff_SMP\n",
      "0   2014       -2.29\n",
      "1   2015       -6.39\n",
      "2   2016       -5.01\n",
      "3   2017       -5.01\n",
      "4   2018        2.88\n",
      "5   2019       -4.37\n",
      "6   2020       -6.95\n",
      "7   2021       -4.69\n",
      "8   2022       -7.23\n",
      "9   2023       -7.15\n",
      "10  2024       -2.74\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "merged_df['year'] = merged_df['date'].dt.year\n",
    "\n",
    "# Group by year and sum the values\n",
    "annual_data = merged_df.groupby('year').sum().reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "annual_data.columns = ['year'] + [f'annual_{col}' for col in annual_data.columns if col != 'year']\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) \n",
    "\n",
    "\n",
    "def percentage_difference(col1, col2):\n",
    "    return (col1 - col2) / col2 * 100\n",
    "\n",
    "suffixes = set(col.split('_')[1] for col in merged_df.columns if '_' in col)\n",
    "\n",
    "yearly_stats_list = []\n",
    "\n",
    "\n",
    "\n",
    "for suffix in suffixes:\n",
    "    taxud_col = f'annual_Y_{suffix}'\n",
    "    gtt_col = f'annual_X_{suffix}'\n",
    "    if taxud_col in annual_data.columns and gtt_col in annual_data.columns:\n",
    "        diff_col = f'%_diff_{suffix}'\n",
    "        annual_data[diff_col] = percentage_difference(annual_data[taxud_col], annual_data[gtt_col])\n",
    "\n",
    "        yearly_stats_list.append(annual_data[['year',diff_col]])\n",
    "\n",
    "if yearly_stats_list:\n",
    "    annual = yearly_stats_list[0]\n",
    "    for df in yearly_stats_list[1:]:\n",
    "        annual = pd.merge(annual, df, on='year')\n",
    "    \n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(annual)\n",
    "else:\n",
    "    print(\"No dataframes to merge\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    month  maximum_error_SMP\n",
      "0       1              18.40\n",
      "1       2              14.50\n",
      "2       3              10.51\n",
      "3       4              24.20\n",
      "4       5              10.12\n",
      "5       6              14.09\n",
      "6       7              12.77\n",
      "7       8              15.10\n",
      "8       9               8.89\n",
      "9      10              16.59\n",
      "10     11               7.52\n",
      "11     12              13.66\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def percentage_difference(col1, col2):\n",
    "    return (col1 - col2) / col2 * 100\n",
    "\n",
    "\n",
    "suffixes = set(col.split('_')[1] for col in merged_df.columns if '_' in col)\n",
    "\n",
    "merged_df['year'] = merged_df['date'].dt.year\n",
    "merged_df['month'] = merged_df['date'].dt.month\n",
    "\n",
    "filtered_df_1 = merged_df[merged_df['year'].isin(years_filtered)]\n",
    "monthly_stats_list = []\n",
    "\n",
    "for suffix in suffixes:\n",
    "    taxud_col = f'Y_{suffix}'\n",
    "    gtt_col = f'X_{suffix}'\n",
    "    if taxud_col in merged_df.columns and gtt_col in merged_df.columns:\n",
    "        diff_col = f'%_diff_{suffix}'\n",
    "        merged_df[diff_col] = percentage_difference(merged_df[taxud_col], merged_df[gtt_col])\n",
    "        filtered_df_1[diff_col] = merged_df[diff_col]  # Ensure the column is also in filtered_df_1\n",
    "\n",
    "        if diff_col in filtered_df_1.columns:\n",
    "            \n",
    "            monthly_stats = filtered_df_1.groupby('month')[diff_col].agg(['mean', 'min', 'max']).reset_index()\n",
    "\n",
    "            monthly_stats.columns = ['month', f'average_percentage_difference_{suffix}', f'min_percentage_difference_{suffix}', f'max_percentage_difference_{suffix}']\n",
    "\n",
    "            monthly_stats[f'maximum_error_{suffix}'] = monthly_stats.apply(\n",
    "                lambda row: max(abs(row[f'min_percentage_difference_{suffix}']), abs(row[f'max_percentage_difference_{suffix}'])) - abs(row[f'average_percentage_difference_{suffix}']),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            monthly_stats_list.append(monthly_stats[['month', f'maximum_error_{suffix}']])\n",
    "\n",
    "if monthly_stats_list:\n",
    "    monthly = monthly_stats_list[0]\n",
    "    for df in monthly_stats_list[1:]:\n",
    "        monthly = pd.merge(monthly, df, on='month', how='outer')\n",
    "    \n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(monthly)\n",
    "else:\n",
    "    print(\"No dataframes to merge\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of worst case scenario"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
