{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  TAXUD_SMP\n",
      "0 2011-01-01   18.60145\n",
      "1 2011-02-01   11.52825\n",
      "2 2011-03-01    0.90160\n",
      "3 2011-04-01    0.81960\n",
      "4 2011-05-01    3.51860\n",
      "5 2011-06-01    1.58327\n",
      "6 2011-07-01    0.27955\n",
      "7 2011-08-01   13.80390\n",
      "8 2011-09-01    1.70283\n",
      "9 2011-10-01   20.44796\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from constants import taxud_mapping, years_filtered, headers\n",
    "from utils import process_calendar_year, process_crop_year  # Import functions\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dfs_TAXUD = []\n",
    "\n",
    "for product in taxud_mapping:\n",
    "    sector = product[\"sector\"]\n",
    "    year_type = product['year']\n",
    "    HS_codes = product[\"HS codes\"]\n",
    "    product_name = product[\"name\"]  # Access the name field\n",
    "\n",
    "    url = f\"https://www.ec.europa.eu/agrifood/api/taxud/weeklyData/import?importCategories=Import%20-%20preferential&importCategories=Import%20-%20most favoured nation&sectors={sector}&{HS_codes}\"\n",
    "    headers = headers\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json() \n",
    "    else:\n",
    "        print(\"Failed to retrieve data\")\n",
    "        data = None\n",
    "\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        if year_type == 'calendar':\n",
    "            monthly_data = process_calendar_year(df,product_name)\n",
    "        else:\n",
    "            monthly_data = process_crop_year(df,product_name)\n",
    "        \n",
    "        monthly_data = monthly_data.rename(columns={'kgEquivalent': product_name})  # Rename column with product name\n",
    "        dfs_TAXUD.append(monthly_data)\n",
    "    else:\n",
    "        print(\"No data to convert to DataFrame\")\n",
    "\n",
    "# Merge all DataFrames on 'date'\n",
    "if dfs_TAXUD:\n",
    "    merged_df = dfs_TAXUD[0]\n",
    "    for df in dfs_TAXUD[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date', how='outer').dropna()\n",
    "    \n",
    "    # Optionally rename the date column if needed\n",
    "    merged_df = merged_df.rename(columns={'date': 'Date'})\n",
    "\n",
    "    # Print the merged DataFrame\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"No dataframes to merge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_script.py\n",
    "import os\n",
    "from database_connection import query_data\n",
    "\n",
    "\n",
    "a_ssh_host = '18.195.40.197'\n",
    "a_ssh_user = 'forge'\n",
    "a_ssh_port = 22\n",
    "a_ssh_private_key = '/Users/germankosenkov/.ssh/id_rsa'\n",
    "a_sql_hostname = 'production.ccq0tjftm3pw.eu-central-1.rds.amazonaws.com'\n",
    "a_sql_username = 'read_only'\n",
    "a_sql_password = 'uC9wkjxyBML5MhWwHLfUM'\n",
    "a_sql_database = 'vesper'\n",
    "a_sql_port = 3306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  GTT_SMP\n",
      "0 2011-01-01  1534.11\n",
      "1 2011-02-01  1306.29\n",
      "2 2011-03-01  1423.56\n",
      "3 2011-04-01   632.95\n",
      "4 2011-05-01  1797.71\n",
      "5 2011-06-01  2211.28\n",
      "6 2011-07-01   908.22\n",
      "7 2011-08-01   557.45\n",
      "8 2011-09-01  1263.04\n",
      "9 2011-10-01  2429.61\n"
     ]
    }
   ],
   "source": [
    "from constants import GTT_mapping\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from database_connection import ssh_tunnel, db_connection, query_data\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "dfs_GTT = []\n",
    "\n",
    "with ssh_tunnel(a_ssh_host, a_ssh_port, a_ssh_user, a_ssh_private_key, a_sql_hostname, a_sql_port) as local_port:\n",
    "    with db_connection(local_port, a_sql_username, a_sql_password, a_sql_database) as conn:\n",
    "        for item in GTT_mapping:\n",
    "            GTT_code = item['GTT_code']\n",
    "            name = item['name']\n",
    "\n",
    "            query = f'''SELECT date, amount\n",
    "                        FROM vesper.total_import_export_figures\n",
    "                        WHERE country_id = 200 AND hs_code = {GTT_code} AND data_interval = 'monthly' AND type = 1 AND date > '2010-12-31'\n",
    "                        ORDER BY date ASC'''\n",
    "\n",
    "            result = query_data(conn, query)\n",
    "            result['date'] = pd.to_datetime(result['date'])\n",
    "            result = result.rename(columns={'amount': f'GTT_{name}'})\n",
    "\n",
    "            dfs_GTT.append(result)\n",
    "\n",
    "if dfs_GTT:\n",
    "    merged_df = dfs_GTT[0]\n",
    "    for df in dfs_GTT[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date', how='outer').dropna()\n",
    "    \n",
    "    merged_df = merged_df.rename(columns={'date': 'Date'})\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"No dataframes to merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  TAXUD_SMP  GTT_SMP\n",
      "0 2011-01-01   18.60145  1534.11\n",
      "1 2011-02-01   11.52825  1306.29\n",
      "2 2011-03-01    0.90160  1423.56\n",
      "3 2011-04-01    0.81960   632.95\n",
      "4 2011-05-01    3.51860  1797.71\n"
     ]
    }
   ],
   "source": [
    "all_dfs = dfs_TAXUD + dfs_GTT\n",
    "\n",
    "def merge_dfs_on_date(df_list):\n",
    "    merged_df = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "    return merged_df\n",
    "\n",
    "# Merge all dataframes\n",
    "merged_df = merge_dfs_on_date(all_dfs).dropna()\n",
    "\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "\n",
    "print(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  %_diff_SMP\n",
      "0   2011      -99.51\n",
      "1   2012      -98.98\n",
      "2   2013      -99.39\n",
      "3   2014      -97.03\n",
      "4   2015      -96.03\n",
      "5   2016      -98.61\n",
      "6   2017      -99.73\n",
      "7   2018      -97.60\n",
      "8   2019      -99.29\n",
      "9   2020      -98.21\n",
      "10  2021      -59.76\n",
      "11  2022      -51.58\n",
      "12  2023      -42.35\n",
      "13  2024      -45.13\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "merged_df['year'] = merged_df['date'].dt.year\n",
    "\n",
    "# Group by year and sum the values\n",
    "annual_data = merged_df.groupby('year').sum().reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "annual_data.columns = ['year'] + [f'annual_{col}' for col in annual_data.columns if col != 'year']\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) \n",
    "\n",
    "\n",
    "def percentage_difference(col1, col2):\n",
    "    return (col1 - col2) / col2 * 100\n",
    "\n",
    "suffixes = set(col.split('_')[1] for col in merged_df.columns if '_' in col)\n",
    "\n",
    "yearly_stats_list = []\n",
    "\n",
    "\n",
    "\n",
    "for suffix in suffixes:\n",
    "    taxud_col = f'annual_TAXUD_{suffix}'\n",
    "    gtt_col = f'annual_GTT_{suffix}'\n",
    "    if taxud_col in annual_data.columns and gtt_col in annual_data.columns:\n",
    "        diff_col = f'%_diff_{suffix}'\n",
    "        annual_data[diff_col] = percentage_difference(annual_data[taxud_col], annual_data[gtt_col])\n",
    "\n",
    "        yearly_stats_list.append(annual_data[['year',diff_col]])\n",
    "\n",
    "if yearly_stats_list:\n",
    "    annual = yearly_stats_list[0]\n",
    "    for df in yearly_stats_list[1:]:\n",
    "        annual = pd.merge(annual, df, on='year')\n",
    "    \n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(annual)\n",
    "else:\n",
    "    print(\"No dataframes to merge\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    month  maximum_error_SMP\n",
      "0       1              11.00\n",
      "1       2              14.15\n",
      "2       3              16.34\n",
      "3       4              15.87\n",
      "4       5              23.38\n",
      "5       6              25.58\n",
      "6       7              20.88\n",
      "7       8              25.10\n",
      "8       9              18.66\n",
      "9      10              25.39\n",
      "10     11              20.02\n",
      "11     12              13.09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def percentage_difference(col1, col2):\n",
    "    return (col1 - col2) / col2 * 100\n",
    "\n",
    "\n",
    "suffixes = set(col.split('_')[1] for col in merged_df.columns if '_' in col)\n",
    "\n",
    "merged_df['year'] = merged_df['date'].dt.year\n",
    "merged_df['month'] = merged_df['date'].dt.month\n",
    "\n",
    "filtered_df_1 = merged_df[merged_df['year'].isin(years_filtered)]\n",
    "monthly_stats_list = []\n",
    "\n",
    "for suffix in suffixes:\n",
    "    taxud_col = f'TAXUD_{suffix}'\n",
    "    gtt_col = f'GTT_{suffix}'\n",
    "    if taxud_col in merged_df.columns and gtt_col in merged_df.columns:\n",
    "        diff_col = f'%_diff_{suffix}'\n",
    "        merged_df[diff_col] = percentage_difference(merged_df[taxud_col], merged_df[gtt_col])\n",
    "        filtered_df_1[diff_col] = merged_df[diff_col]  # Ensure the column is also in filtered_df_1\n",
    "\n",
    "        if diff_col in filtered_df_1.columns:\n",
    "            \n",
    "            monthly_stats = filtered_df_1.groupby('month')[diff_col].agg(['mean', 'min', 'max']).reset_index()\n",
    "\n",
    "            monthly_stats.columns = ['month', f'average_percentage_difference_{suffix}', f'min_percentage_difference_{suffix}', f'max_percentage_difference_{suffix}']\n",
    "\n",
    "            monthly_stats[f'maximum_error_{suffix}'] = monthly_stats.apply(\n",
    "                lambda row: max(abs(row[f'min_percentage_difference_{suffix}']), abs(row[f'max_percentage_difference_{suffix}'])) - abs(row[f'average_percentage_difference_{suffix}']),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            monthly_stats_list.append(monthly_stats[['month', f'maximum_error_{suffix}']])\n",
    "\n",
    "if monthly_stats_list:\n",
    "    monthly = monthly_stats_list[0]\n",
    "    for df in monthly_stats_list[1:]:\n",
    "        monthly = pd.merge(monthly, df, on='month', how='outer')\n",
    "    \n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(monthly)\n",
    "else:\n",
    "    print(\"No dataframes to merge\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of worst case scenario"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
